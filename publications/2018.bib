@article{Niu2018,
abstract = {In this paper, we propose a novel weakly supervised semantic segmentation (WSSS) method that uses image tags as supervision to achieve joint pixel-level localization of the key local structure (KLS) and image-level classification of the aurora images captured by the ground-based optical all-sky imager. First, a patch-scale model (PSM) based on the small-scale structure of aurora is designed to identify the type-specific regions for each training image. Second, a region-scale model is trained with the identified type-specific regions to coarsely localize the KLS from multiple sizes of field of view, based on which the aurora image is classified. Finally, given the predicted image type, the PSM further refines the KLS in a pixel level. By localizing KLS from coarse to fine, the proposed method captures both overall shape with a bottom-up processing and local structure details of aurora in a top-down manner. Extensive experiments on the expert labeled data sets have demonstrated the efficacy of the proposed method in benchmarking with the state-of-the-art WSSS methods.},
author = {Niu, Chuang and Zhang, Jun and Wang, Qian and Liang, Jimin},
doi = {10.1109/TGRS.2018.2848725},
file = {:E$\backslash$:/Mendeley Papers/2018/IEEE Transactions on Geoscience and Remote Sensing/2018 - IEEE Transactions on Geoscience and Remote Sensing - Weakly Supervised Semantic Segmentation for Joint Key Local Structure Locali.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Analytical models,Aurora image analysis,Image segmentation,Ion radiation effects,Magnetosphere,Semantics,Shape,Training,bag of visual words (BoVW),convolutional neural networks (CNNs),weakly supervised semantic segmentation (WSSS).},
pages = {1--14},
publisher = {IEEE},
title = {{Weakly Supervised Semantic Segmentation for Joint Key Local Structure Localization and Classification of Aurora Image}},
year = {2018}
}
@article{Zhan2018,
author = {Zhan, Yonghua and Ehlerding, Emily B. and Shi, Sixiang and Graves, Stephen A. and Goel, Shreya and Engle, Jonathan W. and Liang, Jimin and Cai, Weibo},
doi = {10.1166/jbn.2018.2498},
file = {:E$\backslash$:/Mendeley Papers/2018/Journal of Biomedical Nanotechnology/2018 - Journal of Biomedical Nanotechnology - Intrinsically Zirconium-89-Labeled Manganese Oxide Nanoparticles for In Vivo Dual-Modality.pdf:pdf},
issn = {1550-7033},
journal = {Journal of Biomedical Nanotechnology},
keywords = {magnetic resonance imaging,manganese oxide nanoparticles,positron emission tomography,zirconium-89},
number = {5},
pages = {900--909},
title = {{Intrinsically Zirconium-89-Labeled Manganese Oxide Nanoparticles for In Vivo Dual-Modality Positron Emission Tomography and Magnetic Resonance Imaging}},
url = {http://www.ingentaconnect.com/content/10.1166/jbn.2018.2498},
volume = {14},
year = {2018}
}
@article{Li2018,
author = {Li, Hanrui and Li, Ke and Dai, Yunpeng and Xu, Xinyi and Cao, Xu and Zeng, Qi and He, Huyulong and Pang, Liaojun and Liang, Jimin and Chen, Xueli and Zhan, Yonghua},
doi = {10.1016/j.nano.2018.04.018},
file = {:E$\backslash$:/Mendeley Papers/2018/Nanomedicine Nanotechnology, Biology, and Medicine/2018 - Nanomedicine Nanotechnology, Biology, and Medicine - In vivo near infrared fluorescence imaging and dynamic quantification of pan.pdf:pdf},
issn = {15499642},
journal = {Nanomedicine: Nanotechnology, Biology, and Medicine},
keywords = {Fluorescence imaging,Folic acid,Mesoporous silica nanoparticles,Pancreatic cancer,Quantification,Tumor metastasis},
number = {6},
pages = {1867--1877},
publisher = {Elsevier Inc.},
title = {{In vivo near infrared fluorescence imaging and dynamic quantification of pancreatic metastatic tumors using folic acid conjugated biodegradable mesoporous silica nanoparticles}},
url = {https://doi.org/10.1016/j.nano.2018.04.018},
volume = {14},
year = {2018}
}
@article{Zhao2018,
author = {Zhao, Fengjun and Sun, Feifei and Hou, Yuqing and Chen, Yanrong and Chen, Dongmei and Cao, Xin and Yi, Huangjian and Wang, Bin and He, Xiaowei and Liang, Jimin},
doi = {10.1007/s11517-017-1717-8},
file = {:E$\backslash$:/Mendeley Papers/2018/Medical {\&} Biological Engineering {\&} Computing/2018 - Medical {\&} Biological Engineering {\&} Computing - A monocentric centerline extraction method for ring-like blood vessels.pdf:pdf},
issn = {0140-0118},
journal = {Medical {\&} Biological Engineering {\&} Computing},
keywords = {Centerline extraction,Blood vessels,Information fusion,Monocentric processing,blood vessels,centerline extraction,information fusion,monocentric processing},
number = {4},
pages = {695--707},
publisher = {Medical {\&} Biological Engineering {\&} Computing},
title = {{A monocentric centerline extraction method for ring-like blood vessels}},
url = {http://link.springer.com/10.1007/s11517-017-1717-8},
volume = {56},
year = {2018}
}
@inproceedings{Chen2018,
abstract = {Coronary artery disease (CAD) is one of the leading causes of death worldwide. The computed tomography angiography (CTA) is increasingly used to diagnose CAD due to its non-invasive nature and high-resolution three-dimensional (3D) imaging capability of the coronary artery anatomy. CTA allows for identification and grading of stenosis by evaluating the degree of narrowing of the blood-filled coronary artery lumen. Both identification and grading rely on the precise segmentation of the coronary arteries on CTA images. In this paper, a fully automatic segmentation framework is proposed to extract the coronary arteries from the whole cardiac CTA images. The framework adopts a paired multi-scale 3D deep convolutional neural networks (CNNs) to identify which voxels belong to the vessel lumen. Voxels that may belong to coronary artery lumen are recognized by the first CNN in the pair and both artery positives and artery-like negatives are distinguished by the second one. Each CNN is assigned to a different task. They share the same architecture in common but with different weights. In order to combine local and larger contextual information, we adopt a dual pathway architecture that can process the input image simultaneously on multiple scales. The experiments were performed on a CTA dataset from 44 patients. 35 CTA scans are used for training and the rests for testing. The proposed segmentation framework achieved a mean Dice similarity coefficient (DSC) of 0.8649 and mean surface distance (MSD) of 0.5571 with reference to manual annotations. Experimental results show that the proposed framework is capable of performing complete, accurate and robust segmentation of the coronary arteries.},
author = {Chen, Fei and Li, Yu and Tian, Tian and Cao, Feng and Liang, Jimin},
booktitle = {Medical Imaging 2018: Biomedical Applications in Molecular, Structural, and Functional Imaging},
doi = {10.1117/12.2293289},
file = {:E$\backslash$:/Mendeley Papers/2018/Medical Imaging 2018 Biomedical Applications in Molecular, Structural, and Functional Imaging/2018 - Medical Imaging 2018 Biomedical Applications in Molecular, Structural, and Functional Imaging - Automatic coronary artery lum.pdf:pdf},
isbn = {9781510616455},
issn = {16057422},
keywords = {3D convolutional neural network,Cardiac computed tomography angiography,Coronary arteries segmentation,Deep learning},
number = {March},
pages = {99},
title = {{Automatic coronary artery lumen segmentation in computed tomography angiography using paired multi-scale 3D CNN}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10578/2293289/Automatic-coronary-artery-lumen-segmentation-in-computed-tomography-angiography-using/10.1117/12.2293289.full},
volume = {10578},
year = {2018}
}
